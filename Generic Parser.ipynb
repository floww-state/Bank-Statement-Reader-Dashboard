{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber, re, pandas as pd, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractStatement(path: str, possible_date_formats: str, password: str = None, return_non_trans_sentences: bool = False) -> list[str]:\n",
    "    # Returnes a \\n-seperated string with all the date-like lines from a pdf\n",
    "    with pdfplumber.open(path, password=password) as file:\n",
    "        pages = file.pages # Get all pages from PDF\n",
    "        print(f'Reading pdf from \"{path}\".\\n{len(pages)} pages in pdf')\n",
    "        \n",
    "        words = [page.extract_text() for page in pages] # Extract all words from each page\n",
    "        words = '\\n\\n'.join(words) # Convert list of strings from each page to a single string\n",
    "        sentences = words.splitlines() # Convert string to list of sentences\n",
    "        \n",
    "        trans_sentences = [] # Saves transaction-like sentences\n",
    "        non_trans_sentences = [] # Saves non-transaction-like sentences\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # Check all possible date regexes\n",
    "            date_checks = [bool(re.search(possible_date_format, sentence)) for possible_date_format in possible_date_formats]\n",
    "            is_date = any(date_checks)\n",
    "            # print(is_date)\n",
    "            \n",
    "            if is_date: # If date-like string found\n",
    "                trans_sentences.append(sentence)\n",
    "            \n",
    "            else: # If date-like string not found\n",
    "                non_trans_sentences.append(sentence)\n",
    "        \n",
    "        print(f'{len(trans_sentences)} date-like sentence found (out of {len(sentences)})\\n')\n",
    "        \n",
    "        if return_non_trans_sentences:\n",
    "            return trans_sentences, non_trans_sentences # Return sentences containing date-like values\n",
    "        else:\n",
    "            return trans_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDateFromString(string: str):\n",
    "    # Search for date basis `possible_date_formats` declared earlier\n",
    "    # If match is found w regex at 0, result will be retured and no further search will be done\n",
    "    for regex in possible_date_formats:\n",
    "        result = re.search(regex, string)\n",
    "        if bool(result):\n",
    "            return result.group()\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAmountFromString(string: str):\n",
    "    # Splits basis ' '\n",
    "    # Reverses the list and which even element can be type casted to float will be returned\n",
    "    values = string.split(' ')\n",
    "    values.reverse()\n",
    "    for value in values:\n",
    "        value = value.replace(',', '')\n",
    "        try:\n",
    "            return str(float(value)) # Typecasted to str to avoid e-notation\n",
    "        except ValueError as v:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCommentsFromString(string: str):\n",
    "    result = re.findall('[a-zA-Z]', string)\n",
    "    result = ''.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformStatementV2(transations: list[str]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(transations, columns=['raw_data'])\n",
    "    \n",
    "    # Normalizing the string-like transation data\n",
    "    df['raw_data'] = df['raw_data'].astype(str).str.strip().str.lower()\n",
    "    \n",
    "    # Identifying debit/credit transations\n",
    "    df['is_credit'] = 0\n",
    "    df.loc[(df['raw_data'].astype(str).str.endswith('cr')), 'is_credit'] = 1\n",
    "    \n",
    "    # Removing 'cr' from raw_data for credit transations\n",
    "    df.loc[(df['is_credit'] == 1), 'raw_data'] = df['raw_data'].str[:-2]\n",
    "    \n",
    "    # Extracting date from raw_data\n",
    "    df['date'] = df['raw_data'].apply(lambda x: extractDateFromString(x))\n",
    "    # df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y') # TODO: Handle additional formats\n",
    "    \n",
    "    # Extracting amount from raw_data\n",
    "    df['amount'] = df['raw_data'].apply(lambda x: extractAmountFromString(x))\n",
    "    \n",
    "    # Extracting comments from raw_data\n",
    "    df['comments'] = df['raw_data'].astype(str).str.replace('[^a-zA-Z]', ' ', regex=True, case=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_date_formats = [r'([0-9]{2}/[0-9]{2}/[0-9]{4})', r'([0-9]{2}-[a-zA-Z]{3}-[0-9]{2})'] # CONFIG: Pass additional regexes as you deem fit per your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl(path: str, password: str, regexes: list):\n",
    "    e = extractStatement(path=path, password=password, possible_date_formats=regexes)\n",
    "    t = transformStatementV2(e)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pdf from \"D:\\work\\code_and_stuff\\Bank Statement Reader\\PDFs\\ICICI\\2024-23-11--19-13-26-creditAnnualStmt.pdf\".\n",
      "15 pages in pdf\n",
      "353 date-like sentence found (out of 616)\n",
      "\n",
      "File read: 1\n",
      "(353, 5)\n"
     ]
    }
   ],
   "source": [
    "# folder_path = r'D:\\work\\code_and_stuff\\Bank Statement Reader\\PDFs\\HDFC'\n",
    "# file_paths = [folder_path + '\\\\' + file for file in os.listdir(folder_path)]\n",
    "# dfs = [etl(file_path, '<PUT PASSWORD HERE>', possible_date_formats) for file_path in file_paths]\n",
    "\n",
    "file_paths = [r'D:\\work\\code_and_stuff\\Bank Statement Reader\\PDFs\\ICICI\\2024-23-11--19-13-26-creditAnnualStmt.pdf']\n",
    "dfs = [etl(file_path, None, possible_date_formats) for file_path in file_paths]\n",
    "\n",
    "print(f'File read: {len(dfs)}')\n",
    "\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "print(df.shape)\n",
    "\n",
    "df['bank'] = 'ICICI'\n",
    "\n",
    "df.to_csv(r'D:\\work\\code_and_stuff\\Bank Statement Reader\\Processed\\ICICI.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
